{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Loss optimizing\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Prediction from a single training loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# check performance against the test data\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.155811  [    0/60000]\n",
      "loss: 1.149098  [ 6400/60000]\n",
      "loss: 0.967910  [12800/60000]\n",
      "loss: 1.117562  [19200/60000]\n",
      "loss: 0.983180  [25600/60000]\n",
      "loss: 1.016441  [32000/60000]\n",
      "loss: 1.048292  [38400/60000]\n",
      "loss: 0.986556  [44800/60000]\n",
      "loss: 1.034780  [51200/60000]\n",
      "loss: 0.966576  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.979983 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.035746  [    0/60000]\n",
      "loss: 1.049853  [ 6400/60000]\n",
      "loss: 0.850771  [12800/60000]\n",
      "loss: 1.026622  [19200/60000]\n",
      "loss: 0.896197  [25600/60000]\n",
      "loss: 0.923666  [32000/60000]\n",
      "loss: 0.973715  [38400/60000]\n",
      "loss: 0.912606  [44800/60000]\n",
      "loss: 0.956827  [51200/60000]\n",
      "loss: 0.902922  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.907970 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.947487  [    0/60000]\n",
      "loss: 0.981632  [ 6400/60000]\n",
      "loss: 0.767633  [12800/60000]\n",
      "loss: 0.962675  [19200/60000]\n",
      "loss: 0.838729  [25600/60000]\n",
      "loss: 0.855680  [32000/60000]\n",
      "loss: 0.921509  [38400/60000]\n",
      "loss: 0.862994  [44800/60000]\n",
      "loss: 0.900624  [51200/60000]\n",
      "loss: 0.857535  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.856042 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.879465  [    0/60000]\n",
      "loss: 0.930493  [ 6400/60000]\n",
      "loss: 0.705801  [12800/60000]\n",
      "loss: 0.914700  [19200/60000]\n",
      "loss: 0.797798  [25600/60000]\n",
      "loss: 0.804031  [32000/60000]\n",
      "loss: 0.881638  [38400/60000]\n",
      "loss: 0.828078  [44800/60000]\n",
      "loss: 0.858249  [51200/60000]\n",
      "loss: 0.823173  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.816577 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.824776  [    0/60000]\n",
      "loss: 0.889548  [ 6400/60000]\n",
      "loss: 0.657960  [12800/60000]\n",
      "loss: 0.877361  [19200/60000]\n",
      "loss: 0.766874  [25600/60000]\n",
      "loss: 0.763888  [32000/60000]\n",
      "loss: 0.849209  [38400/60000]\n",
      "loss: 0.802055  [44800/60000]\n",
      "loss: 0.825087  [51200/60000]\n",
      "loss: 0.795886  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.785081 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.779456  [    0/60000]\n",
      "loss: 0.855150  [ 6400/60000]\n",
      "loss: 0.619500  [12800/60000]\n",
      "loss: 0.847488  [19200/60000]\n",
      "loss: 0.742161  [25600/60000]\n",
      "loss: 0.732082  [32000/60000]\n",
      "loss: 0.821233  [38400/60000]\n",
      "loss: 0.781631  [44800/60000]\n",
      "loss: 0.798051  [51200/60000]\n",
      "loss: 0.773022  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.758847 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.740865  [    0/60000]\n",
      "loss: 0.825121  [ 6400/60000]\n",
      "loss: 0.587820  [12800/60000]\n",
      "loss: 0.823049  [19200/60000]\n",
      "loss: 0.721454  [25600/60000]\n",
      "loss: 0.706276  [32000/60000]\n",
      "loss: 0.796143  [38400/60000]\n",
      "loss: 0.764273  [44800/60000]\n",
      "loss: 0.775273  [51200/60000]\n",
      "loss: 0.753192  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.736236 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.707436  [    0/60000]\n",
      "loss: 0.798234  [ 6400/60000]\n",
      "loss: 0.561047  [12800/60000]\n",
      "loss: 0.802413  [19200/60000]\n",
      "loss: 0.703469  [25600/60000]\n",
      "loss: 0.684880  [32000/60000]\n",
      "loss: 0.773066  [38400/60000]\n",
      "loss: 0.749079  [44800/60000]\n",
      "loss: 0.755693  [51200/60000]\n",
      "loss: 0.735615  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.716274 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.678022  [    0/60000]\n",
      "loss: 0.773751  [ 6400/60000]\n",
      "loss: 0.538003  [12800/60000]\n",
      "loss: 0.784621  [19200/60000]\n",
      "loss: 0.687779  [25600/60000]\n",
      "loss: 0.666998  [32000/60000]\n",
      "loss: 0.751448  [38400/60000]\n",
      "loss: 0.735426  [44800/60000]\n",
      "loss: 0.738669  [51200/60000]\n",
      "loss: 0.719733  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.698347 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.652076  [    0/60000]\n",
      "loss: 0.751254  [ 6400/60000]\n",
      "loss: 0.517935  [12800/60000]\n",
      "loss: 0.768901  [19200/60000]\n",
      "loss: 0.673811  [25600/60000]\n",
      "loss: 0.651793  [32000/60000]\n",
      "loss: 0.731362  [38400/60000]\n",
      "loss: 0.723219  [44800/60000]\n",
      "loss: 0.723455  [51200/60000]\n",
      "loss: 0.705218  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.682063 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.629021  [    0/60000]\n",
      "loss: 0.730636  [ 6400/60000]\n",
      "loss: 0.500327  [12800/60000]\n",
      "loss: 0.754925  [19200/60000]\n",
      "loss: 0.661483  [25600/60000]\n",
      "loss: 0.638869  [32000/60000]\n",
      "loss: 0.712463  [38400/60000]\n",
      "loss: 0.712179  [44800/60000]\n",
      "loss: 0.710196  [51200/60000]\n",
      "loss: 0.691739  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.667247 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.608507  [    0/60000]\n",
      "loss: 0.711738  [ 6400/60000]\n",
      "loss: 0.484593  [12800/60000]\n",
      "loss: 0.742300  [19200/60000]\n",
      "loss: 0.650441  [25600/60000]\n",
      "loss: 0.627756  [32000/60000]\n",
      "loss: 0.694802  [38400/60000]\n",
      "loss: 0.702353  [44800/60000]\n",
      "loss: 0.698479  [51200/60000]\n",
      "loss: 0.679241  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.653713 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.590105  [    0/60000]\n",
      "loss: 0.694385  [ 6400/60000]\n",
      "loss: 0.470510  [12800/60000]\n",
      "loss: 0.730575  [19200/60000]\n",
      "loss: 0.640650  [25600/60000]\n",
      "loss: 0.618144  [32000/60000]\n",
      "loss: 0.678376  [38400/60000]\n",
      "loss: 0.693706  [44800/60000]\n",
      "loss: 0.688248  [51200/60000]\n",
      "loss: 0.667369  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.641324 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.573640  [    0/60000]\n",
      "loss: 0.678395  [ 6400/60000]\n",
      "loss: 0.457889  [12800/60000]\n",
      "loss: 0.719772  [19200/60000]\n",
      "loss: 0.631578  [25600/60000]\n",
      "loss: 0.609824  [32000/60000]\n",
      "loss: 0.663008  [38400/60000]\n",
      "loss: 0.686029  [44800/60000]\n",
      "loss: 0.679473  [51200/60000]\n",
      "loss: 0.656331  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.629985 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.558699  [    0/60000]\n",
      "loss: 0.663768  [ 6400/60000]\n",
      "loss: 0.446518  [12800/60000]\n",
      "loss: 0.709762  [19200/60000]\n",
      "loss: 0.623467  [25600/60000]\n",
      "loss: 0.602523  [32000/60000]\n",
      "loss: 0.648726  [38400/60000]\n",
      "loss: 0.679471  [44800/60000]\n",
      "loss: 0.672071  [51200/60000]\n",
      "loss: 0.645921  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.619593 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.545147  [    0/60000]\n",
      "loss: 0.650345  [ 6400/60000]\n",
      "loss: 0.436090  [12800/60000]\n",
      "loss: 0.700331  [19200/60000]\n",
      "loss: 0.615743  [25600/60000]\n",
      "loss: 0.595731  [32000/60000]\n",
      "loss: 0.635418  [38400/60000]\n",
      "loss: 0.673849  [44800/60000]\n",
      "loss: 0.665705  [51200/60000]\n",
      "loss: 0.635879  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.610044 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.532830  [    0/60000]\n",
      "loss: 0.637915  [ 6400/60000]\n",
      "loss: 0.426637  [12800/60000]\n",
      "loss: 0.691477  [19200/60000]\n",
      "loss: 0.608603  [25600/60000]\n",
      "loss: 0.589683  [32000/60000]\n",
      "loss: 0.623111  [38400/60000]\n",
      "loss: 0.669155  [44800/60000]\n",
      "loss: 0.660156  [51200/60000]\n",
      "loss: 0.626232  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.601242 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.521514  [    0/60000]\n",
      "loss: 0.626465  [ 6400/60000]\n",
      "loss: 0.417941  [12800/60000]\n",
      "loss: 0.683003  [19200/60000]\n",
      "loss: 0.601621  [25600/60000]\n",
      "loss: 0.583896  [32000/60000]\n",
      "loss: 0.611666  [38400/60000]\n",
      "loss: 0.665376  [44800/60000]\n",
      "loss: 0.655535  [51200/60000]\n",
      "loss: 0.617010  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.593104 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.510972  [    0/60000]\n",
      "loss: 0.615932  [ 6400/60000]\n",
      "loss: 0.409917  [12800/60000]\n",
      "loss: 0.675058  [19200/60000]\n",
      "loss: 0.594887  [25600/60000]\n",
      "loss: 0.578482  [32000/60000]\n",
      "loss: 0.600963  [38400/60000]\n",
      "loss: 0.662232  [44800/60000]\n",
      "loss: 0.651539  [51200/60000]\n",
      "loss: 0.608060  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.585553 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.501133  [    0/60000]\n",
      "loss: 0.606045  [ 6400/60000]\n",
      "loss: 0.402556  [12800/60000]\n",
      "loss: 0.667407  [19200/60000]\n",
      "loss: 0.588279  [25600/60000]\n",
      "loss: 0.573327  [32000/60000]\n",
      "loss: 0.590981  [38400/60000]\n",
      "loss: 0.659821  [44800/60000]\n",
      "loss: 0.648117  [51200/60000]\n",
      "loss: 0.599364  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.578542 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.491907  [    0/60000]\n",
      "loss: 0.596907  [ 6400/60000]\n",
      "loss: 0.395685  [12800/60000]\n",
      "loss: 0.660085  [19200/60000]\n",
      "loss: 0.581773  [25600/60000]\n",
      "loss: 0.568255  [32000/60000]\n",
      "loss: 0.581735  [38400/60000]\n",
      "loss: 0.657796  [44800/60000]\n",
      "loss: 0.645137  [51200/60000]\n",
      "loss: 0.590902  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.572016 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.483253  [    0/60000]\n",
      "loss: 0.588445  [ 6400/60000]\n",
      "loss: 0.389317  [12800/60000]\n",
      "loss: 0.652992  [19200/60000]\n",
      "loss: 0.575365  [25600/60000]\n",
      "loss: 0.563411  [32000/60000]\n",
      "loss: 0.573122  [38400/60000]\n",
      "loss: 0.656349  [44800/60000]\n",
      "loss: 0.642508  [51200/60000]\n",
      "loss: 0.582613  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.565930 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.475084  [    0/60000]\n",
      "loss: 0.580534  [ 6400/60000]\n",
      "loss: 0.383300  [12800/60000]\n",
      "loss: 0.646243  [19200/60000]\n",
      "loss: 0.569055  [25600/60000]\n",
      "loss: 0.558575  [32000/60000]\n",
      "loss: 0.565056  [38400/60000]\n",
      "loss: 0.655314  [44800/60000]\n",
      "loss: 0.640161  [51200/60000]\n",
      "loss: 0.574606  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.560238 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.467219  [    0/60000]\n",
      "loss: 0.573129  [ 6400/60000]\n",
      "loss: 0.377665  [12800/60000]\n",
      "loss: 0.639772  [19200/60000]\n",
      "loss: 0.562862  [25600/60000]\n",
      "loss: 0.553911  [32000/60000]\n",
      "loss: 0.557509  [38400/60000]\n",
      "loss: 0.654602  [44800/60000]\n",
      "loss: 0.638077  [51200/60000]\n",
      "loss: 0.566710  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.554914 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.459738  [    0/60000]\n",
      "loss: 0.566252  [ 6400/60000]\n",
      "loss: 0.372350  [12800/60000]\n",
      "loss: 0.633469  [19200/60000]\n",
      "loss: 0.556771  [25600/60000]\n",
      "loss: 0.549063  [32000/60000]\n",
      "loss: 0.550459  [38400/60000]\n",
      "loss: 0.654254  [44800/60000]\n",
      "loss: 0.636133  [51200/60000]\n",
      "loss: 0.559037  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.549935 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}