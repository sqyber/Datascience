{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import time\n",
    "#PATH PROCESS\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import nibabel as nib\n",
    "import csv\n",
    "#IMAGE PROCESS\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from scipy.ndimage.filters import convolve\n",
    "from skimage import data, io, filters\n",
    "import skimage\n",
    "from skimage.morphology import convex_hull_image, erosion\n",
    "from IPython import display\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "#SCALER & TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#ACCURACY CONTROL\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#OPTIMIZER\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n",
    "#MODEL LAYERS\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose,LeakyReLU, GaussianNoise, GlobalMaxPooling2D, ReLU, Input, Concatenate\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16,VGG19,inception_v3\n",
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import keras.utils\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras.models import Model\n",
    "#IGNORING WARNINGS\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying: Tensorflow gpu enable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much more complex and regressive problem related to predicting solar flares\n",
    "Goal is to create a deep learning model to predict solar flares based on the 800k jpeg dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up files and checking tables/csv's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "Main_Path = Path('SDOBenchmark_example/training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "Main_Train_CSV = list(Main_Path.glob(r\"**/*.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(Main_Train_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "Train_CSV = Main_Train_CSV[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDOBenchmark_example\\training\\meta_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(Train_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "Reading_CSV = pd.read_csv(Train_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'start', 'end', 'peak_flux'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n"
     ]
    }
   ],
   "source": [
    "print(len(Reading_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id                          start  \\\n",
      "0    11389_2012_01_01_19_06_00_0  2012-01-01 07:06:00.000000000   \n",
      "1    11390_2012_01_03_02_22_01_1  2012-01-03 14:22:00.000000000   \n",
      "2    11392_2012_01_06_00_09_01_0  2012-01-05 12:09:01.000000000   \n",
      "3    11388_2012_01_07_02_27_01_0  2012-01-06 14:27:01.000000000   \n",
      "4    11394_2012_01_07_12_00_00_0  2012-01-07 00:00:00.000000000   \n",
      "..                           ...                            ...   \n",
      "411  12676_2017_09_03_12_00_00_5  2017-09-05 12:00:00.000000000   \n",
      "412  12674_2017_09_05_02_22_00_5  2017-09-08 20:01:07.753754283   \n",
      "413  12683_2017_09_28_01_01_00_3  2017-09-30 13:19:00.999999999   \n",
      "414  12682_2017_10_05_02_49_59_0  2017-10-04 14:49:59.000000000   \n",
      "415  12683_2017_10_06_16_35_59_0  2017-10-06 04:35:59.000000000   \n",
      "\n",
      "                               end     peak_flux  \n",
      "0    2012-01-01 19:06:00.000000000  1.882353e-06  \n",
      "1    2012-01-04 02:22:00.000000000  7.529412e-07  \n",
      "2    2012-01-06 00:09:01.000000000  3.058824e-06  \n",
      "3    2012-01-07 02:27:01.000000000  5.764706e-06  \n",
      "4    2012-01-07 12:00:00.000000000  1.000000e-09  \n",
      "..                             ...           ...  \n",
      "411  2017-09-06 00:00:00.000000000  1.000000e-09  \n",
      "412  2017-09-09 08:01:07.753754283  1.000000e-09  \n",
      "413  2017-10-01 01:19:00.999999999  1.000000e-09  \n",
      "414  2017-10-05 02:49:59.000000000  1.647059e-07  \n",
      "415  2017-10-06 16:35:59.000000000  5.411765e-07  \n",
      "\n",
      "[416 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           0\n",
      "start        0\n",
      "end          0\n",
      "peak_flux    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8823529411764705e-06\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"peak_flux\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-04 14:49:59.000000000\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"start\"][414])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-04\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"start\"][414][0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform date and time to a useable form"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Reading_CSV[\"start\"][414][0:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "Test_Date_Transform = Reading_CSV[\"start\"][414][0:10].replace(\"-\",\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171004\n"
     ]
    }
   ],
   "source": [
    "print(Test_Date_Transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "Test_Date_Array = np.array(int(Test_Date_Transform))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Test_Date_Array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin Data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "JPG_Path = list(Main_Path.glob(r\"**/*.jpg\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "Sorted_JPG_Path = sorted(JPG_Path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "Reading_CSV[\"New_ID\"] = Sorted_JPG_Path[40:457]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id                          start  \\\n",
      "0    11389_2012_01_01_19_06_00_0  2012-01-01 07:06:00.000000000   \n",
      "1    11390_2012_01_03_02_22_01_1  2012-01-03 14:22:00.000000000   \n",
      "2    11392_2012_01_06_00_09_01_0  2012-01-05 12:09:01.000000000   \n",
      "3    11388_2012_01_07_02_27_01_0  2012-01-06 14:27:01.000000000   \n",
      "4    11394_2012_01_07_12_00_00_0  2012-01-07 00:00:00.000000000   \n",
      "..                           ...                            ...   \n",
      "411  12676_2017_09_03_12_00_00_5  2017-09-05 12:00:00.000000000   \n",
      "412  12674_2017_09_05_02_22_00_5  2017-09-08 20:01:07.753754283   \n",
      "413  12683_2017_09_28_01_01_00_3  2017-09-30 13:19:00.999999999   \n",
      "414  12682_2017_10_05_02_49_59_0  2017-10-04 14:49:59.000000000   \n",
      "415  12683_2017_10_06_16_35_59_0  2017-10-06 04:35:59.000000000   \n",
      "\n",
      "                               end     peak_flux  \\\n",
      "0    2012-01-01 19:06:00.000000000  1.882353e-06   \n",
      "1    2012-01-04 02:22:00.000000000  7.529412e-07   \n",
      "2    2012-01-06 00:09:01.000000000  3.058824e-06   \n",
      "3    2012-01-07 02:27:01.000000000  5.764706e-06   \n",
      "4    2012-01-07 12:00:00.000000000  1.000000e-09   \n",
      "..                             ...           ...   \n",
      "411  2017-09-06 00:00:00.000000000  1.000000e-09   \n",
      "412  2017-09-09 08:01:07.753754283  1.000000e-09   \n",
      "413  2017-10-01 01:19:00.999999999  1.000000e-09   \n",
      "414  2017-10-05 02:49:59.000000000  1.647059e-07   \n",
      "415  2017-10-06 16:35:59.000000000  5.411765e-07   \n",
      "\n",
      "                                                New_ID  \n",
      "0    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "1    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "2    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "3    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "4    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "..                                                 ...  \n",
      "411  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "412  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "413  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "414  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "415  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "\n",
      "[416 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDOBenchmark_example\\training\\11388\\2012_01_07_02_27_01_0\\2012-01-07T005701__131.jpg\n",
      "------------------------------\n",
      "11389_2012_01_01_19_06_00_0\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"New_ID\"][0])\n",
    "print(\"---\"*10)\n",
    "print(Reading_CSV[\"id\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building New data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "New_Start = []\n",
    "New_End = []\n",
    "New_Path = []\n",
    "\n",
    "for x_start, x_end, x_path in zip(Reading_CSV.start.values,Reading_CSV.end.values,Reading_CSV.New_ID.values):\n",
    "\n",
    "    x_start = x_start[0:10]\n",
    "    x_start = x_start.replace(\"-\",\"\")\n",
    "    x_start = np.array(x_start,dtype=\"float32\")\n",
    "\n",
    "    x_end = x_end[0:10]\n",
    "    x_end = x_end.replace(\"-\",\"\")\n",
    "    x_end = np.array(x_end,dtype=\"float32\")\n",
    "\n",
    "    New_Start.append(x_start)\n",
    "    New_End.append(x_end)\n",
    "    New_Path.append(x_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN START:  417\n",
      "LEN END:  417\n",
      "LEN PATH:  417\n"
     ]
    }
   ],
   "source": [
    "print(\"LEN START: \", len(New_Start))\n",
    "print(\"LEN END: \", len(New_End))\n",
    "print(\"LEN PATH: \", len(New_Path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120100.0\n",
      "--------------------\n",
      "20120100.0\n",
      "--------------------\n",
      "SDOBenchmark_example\\training\\11388\\2012_01_07_02_27_01_0\\2012-01-07T005701__131.jpg\n"
     ]
    }
   ],
   "source": [
    "print(New_Start[0])\n",
    "print(\"--\"*10)\n",
    "print(New_End[0])\n",
    "print(\"--\"*10)\n",
    "print(New_Path[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "Start_Series = pd.Series(New_Start,name=\"START\").astype(np.float32)\n",
    "End_Series = pd.Series(New_End,name=\"END\").astype(np.float32)\n",
    "Path_Series = pd.Series(New_Path,name=\"PATH\").astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "Main_Data = pd.concat([Path_Series,Start_Series,End_Series],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  PATH       START         END\n",
      "0    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120100.0  20120100.0\n",
      "1    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120104.0  20120104.0\n",
      "2    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120104.0  20120106.0\n",
      "3    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120106.0  20120108.0\n",
      "4    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120108.0  20120108.0\n",
      "..                                                 ...         ...         ...\n",
      "411  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170904.0  20170906.0\n",
      "412  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170908.0  20170908.0\n",
      "413  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170930.0  20171000.0\n",
      "414  SDOBenchmark_example\\training\\11391\\2012_01_09...  20171004.0  20171004.0\n",
      "415  SDOBenchmark_example\\training\\11391\\2012_01_09...  20171006.0  20171006.0\n",
      "\n",
      "[416 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Main_Data.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing various image display configurations\n",
    "Vision\n",
    "Single"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2425a5a6a60>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][33]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Example_IMG.shape)\n",
    "plt.ylabel(Example_IMG.size)\n",
    "plt.imshow(Example_IMG)\n",
    "\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "\n",
    "    Reading_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][indexing]),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    operations.set_xlabel(Reading_IMG.shape)\n",
    "    operations.set_ylabel(Reading_IMG.size)\n",
    "    operations.imshow(Reading_IMG)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2425b6bb040>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2D\n",
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][13]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Example_IMG[:,:,0].shape)\n",
    "plt.ylabel(Example_IMG[:,:,0].size)\n",
    "plt.imshow(Example_IMG[:,:,0])\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Treshold image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x24245980160>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][13]),cv2.COLOR_BGR2RGB)\n",
    "_,Threshold_IMG = cv2.threshold(Example_IMG,200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Threshold_IMG.shape)\n",
    "plt.ylabel(Threshold_IMG.size)\n",
    "plt.imshow(Threshold_IMG)\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Varius other image types can be used such as Layer concat, Countours, Canny-treshold concat etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data transformation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X_Start = []\n",
    "X_End = []\n",
    "X_Image = []\n",
    "\n",
    "for img,start_i, end_i in zip(Main_Data.PATH.values, Main_Data.START.values, Main_Data.END.values):\n",
    "    Picking_IMG = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "    Picking_IMG = cv2.resize(Picking_IMG, (180,180))\n",
    "    Picking_IMG = Picking_IMG / 255.\n",
    "\n",
    "    X_Image.append(Picking_IMG)\n",
    "    X_Start.append(start_i)\n",
    "    X_End.append(end_i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417,)\n",
      "(417,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.array(X_Image)))\n",
    "print(np.shape(np.array(X_Start)))\n",
    "print(np.shape(np.array(X_End)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "Train_JPG = np.array(X_Image,dtype = \"float32\")\n",
    "Train_START = np.array(X_Start,dtype=\"float32\")\n",
    "Train_END = np.array(X_End,dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(Train_JPG.shape)\n",
    "print(Train_START.shape)\n",
    "print(Train_END.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417,)\n",
      "(417,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "Scalar_Function = MinMaxScaler()\n",
    "\n",
    "Train_START_R = Scalar_Function.fit_transform(Train_START.reshape(-1,1))\n",
    "Train_END_R = Scalar_Function.fit_transform(Train_END.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auto-encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "X_Mask = []\n",
    "X_New_IMG = []\n",
    "\n",
    "for img_i in Main_Data.PATH.values:\n",
    "    Picking_IMG = cv2.cvtColor(cv2.imread(img_i),cv2.COLOR_BGR2RGB)\n",
    "    _,Threshold_IMG = cv2.threshold(Picking_IMG,200,255,cv2.THRESH_BINARY)\n",
    "    Canny_IMG = cv2.Canny(Threshold_IMG, 10,100)\n",
    "\n",
    "    Copy_Main = Picking_IMG.copy()\n",
    "    Copy_Main[Canny_IMG == 255] = [255,0,0]\n",
    "\n",
    "    Copy_Main = cv2.resize(Copy_Main, (180,180))\n",
    "    Copy_Main = Copy_Main / 255.\n",
    "\n",
    "    Picking_IMG = cv2.resize(Picking_IMG, (180,180))\n",
    "    Picking_IMG = Picking_IMG / 255.\n",
    "\n",
    "    X_Mask.append(Copy_Main)\n",
    "    X_New_IMG.append(Picking_IMG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "X_Mask = np.array(X_Mask,dtype=\"float32\")\n",
    "X_New_IMG = np.array(X_New_IMG,dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_New_IMG.shape)\n",
    "print(X_Mask.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 179.5, 179.5, -0.5)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure,axis = plt.subplots(1,2, figsize=(15,15))\n",
    "\n",
    "axis[0].imshow(X_New_IMG[0])\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(X_Mask[0])\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 179.5, 179.5, -0.5)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure,axis = plt.subplots(1,2, figsize=(15,15))\n",
    "\n",
    "axis[0].imshow(X_New_IMG[100])\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(X_Mask[100])\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encoder model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters / Callbacks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\n",
    "Checkpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\", save_best_only=True, save_weights_only=True, filepath=\"./modelcheck\")\n",
    "Reduce_Model = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "compile_loss = \"binary_crossentropy\"\n",
    "compile_optimizers = Adam(lr=0.0000001)\n",
    "output_class = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Structure, building model layers. 4 convolution layers into 4 transposed convolutions. he_normal weights matrix and padding for dimension consistency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "E_AE = Sequential()\n",
    "\n",
    "E_AE.add(Conv2D(32,(5,5), kernel_initializer= 'he_normal', use_bias=True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "E_AE.add(Conv2D(64,(5,5), kernel_initializer= 'he_normal',use_bias= True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "E_AE.add(Conv2D(128,(5,5), kernel_initializer= 'he_normal', use_bias= True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "E_AE.add(Conv2D(256,(5,5), kernel_initializer= 'he_normal', use_bias=True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "D_AE = Sequential()\n",
    "\n",
    "D_AE.add(Conv2DTranspose(128,(5,5), padding=\"valid\"))\n",
    "D_AE.add(ReLU())\n",
    "\n",
    "D_AE.add(Conv2DTranspose(64,(5,5), padding=\"valid\"))\n",
    "D_AE.add(ReLU())\n",
    "\n",
    "D_AE.add(Conv2DTranspose(32,(5,5), padding=\"valid\"))\n",
    "D_AE.add(ReLU())\n",
    "\n",
    "D_AE.add(Conv2DTranspose(output_class,(5,5)))\n",
    "D_AE.add(ReLU())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "Auto_Encoder = Sequential([E_AE, D_AE])\n",
    "Auto_Encoder.compile(loss=compile_loss, optimizer=compile_optimizers, metrics=[\"mse\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training, note the model is very heavy on the resources recommended to use a high end cpu or gpu accelerated tensorflow."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Model_Autoencoder = Auto_Encoder.fit(X_New_IMG, X_Mask, epochs=55, callbacks=[Checkpoint_Model])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      " 5/14 [=========>....................] - ETA: 10:18 - loss: 2.7946 - mse: 0.1440\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-107-ca56a27452a7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mModel_Autoencoder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAuto_Encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_New_IMG\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_Mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m55\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mCheckpoint_Model\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1182\u001B[0m                 _r=1):\n\u001B[0;32m   1183\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1184\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1185\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1186\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    883\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    884\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 885\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    886\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    887\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    915\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    916\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 917\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    918\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    919\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3037\u001B[0m       (graph_function,\n\u001B[0;32m   3038\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   3040\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   3041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1961\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1962\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1963\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1964\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1965\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    590\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 591\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ff1620ce",
   "language": "python",
   "display_name": "PyCharm (DataScience)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}