{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import time\n",
    "#PATH PROCESS\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import nibabel as nib\n",
    "import csv\n",
    "#IMAGE PROCESS\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from scipy.ndimage.filters import convolve\n",
    "from skimage import data, io, filters\n",
    "import skimage\n",
    "from skimage.morphology import convex_hull_image, erosion\n",
    "from IPython import display\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "#SCALER & TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#ACCURACY CONTROL\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#OPTIMIZER\n",
    "#from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n",
    "#MODEL LAYERS\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose,LeakyReLU, GaussianNoise, GlobalMaxPooling2D, ReLU, Input, Concatenate\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "#from keras.applications import VGG16,VGG19,inception_v3\n",
    "from keras import backend as K\n",
    "#from keras.utils import plot_model\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras.models import Model\n",
    "#IGNORING WARNINGS\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much more complex and regressive problem related to predicting solar flares\n",
    "\"This dataset was created by Roman Bolzern and Michael Aerni from the Institute for Data Science, FHNW, Switzerland. We owe our thanks to the SDO satellite mission, and to JSOC Stanford for providing the raw data.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up files and checking tables/csv's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "Main_Path = Path('SDOBenchmark_example/training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "Main_Train_CSV = list(Main_Path.glob(r\"**/*.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(Main_Train_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "Train_CSV = Main_Train_CSV[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDOBenchmark_example\\training\\meta_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(Train_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "Reading_CSV = pd.read_csv(Train_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'start', 'end', 'peak_flux'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n"
     ]
    }
   ],
   "source": [
    "print(len(Reading_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id                          start  \\\n",
      "0    11389_2012_01_01_19_06_00_0  2012-01-01 07:06:00.000000000   \n",
      "1    11390_2012_01_03_02_22_01_1  2012-01-03 14:22:00.000000000   \n",
      "2    11392_2012_01_06_00_09_01_0  2012-01-05 12:09:01.000000000   \n",
      "3    11388_2012_01_07_02_27_01_0  2012-01-06 14:27:01.000000000   \n",
      "4    11394_2012_01_07_12_00_00_0  2012-01-07 00:00:00.000000000   \n",
      "..                           ...                            ...   \n",
      "411  12676_2017_09_03_12_00_00_5  2017-09-05 12:00:00.000000000   \n",
      "412  12674_2017_09_05_02_22_00_5  2017-09-08 20:01:07.753754283   \n",
      "413  12683_2017_09_28_01_01_00_3  2017-09-30 13:19:00.999999999   \n",
      "414  12682_2017_10_05_02_49_59_0  2017-10-04 14:49:59.000000000   \n",
      "415  12683_2017_10_06_16_35_59_0  2017-10-06 04:35:59.000000000   \n",
      "\n",
      "                               end     peak_flux  \n",
      "0    2012-01-01 19:06:00.000000000  1.882353e-06  \n",
      "1    2012-01-04 02:22:00.000000000  7.529412e-07  \n",
      "2    2012-01-06 00:09:01.000000000  3.058824e-06  \n",
      "3    2012-01-07 02:27:01.000000000  5.764706e-06  \n",
      "4    2012-01-07 12:00:00.000000000  1.000000e-09  \n",
      "..                             ...           ...  \n",
      "411  2017-09-06 00:00:00.000000000  1.000000e-09  \n",
      "412  2017-09-09 08:01:07.753754283  1.000000e-09  \n",
      "413  2017-10-01 01:19:00.999999999  1.000000e-09  \n",
      "414  2017-10-05 02:49:59.000000000  1.647059e-07  \n",
      "415  2017-10-06 16:35:59.000000000  5.411765e-07  \n",
      "\n",
      "[416 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           0\n",
      "start        0\n",
      "end          0\n",
      "peak_flux    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8823529411764705e-06\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"peak_flux\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-04 14:49:59.000000000\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"start\"][414])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-04\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"start\"][414][0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform date and time to a useable form"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Reading_CSV[\"start\"][414][0:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "Test_Date_Transform = Reading_CSV[\"start\"][414][0:10].replace(\"-\",\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171004\n"
     ]
    }
   ],
   "source": [
    "print(Test_Date_Transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "Test_Date_Array = np.array(int(Test_Date_Transform))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Test_Date_Array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin Data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "JPG_Path = list(Main_Path.glob(r\"**/*.jpg\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "Sorted_JPG_Path = sorted(JPG_Path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "Reading_CSV[\"New_ID\"] = Sorted_JPG_Path[40:457]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id                          start  \\\n",
      "0    11389_2012_01_01_19_06_00_0  2012-01-01 07:06:00.000000000   \n",
      "1    11390_2012_01_03_02_22_01_1  2012-01-03 14:22:00.000000000   \n",
      "2    11392_2012_01_06_00_09_01_0  2012-01-05 12:09:01.000000000   \n",
      "3    11388_2012_01_07_02_27_01_0  2012-01-06 14:27:01.000000000   \n",
      "4    11394_2012_01_07_12_00_00_0  2012-01-07 00:00:00.000000000   \n",
      "..                           ...                            ...   \n",
      "411  12676_2017_09_03_12_00_00_5  2017-09-05 12:00:00.000000000   \n",
      "412  12674_2017_09_05_02_22_00_5  2017-09-08 20:01:07.753754283   \n",
      "413  12683_2017_09_28_01_01_00_3  2017-09-30 13:19:00.999999999   \n",
      "414  12682_2017_10_05_02_49_59_0  2017-10-04 14:49:59.000000000   \n",
      "415  12683_2017_10_06_16_35_59_0  2017-10-06 04:35:59.000000000   \n",
      "\n",
      "                               end     peak_flux  \\\n",
      "0    2012-01-01 19:06:00.000000000  1.882353e-06   \n",
      "1    2012-01-04 02:22:00.000000000  7.529412e-07   \n",
      "2    2012-01-06 00:09:01.000000000  3.058824e-06   \n",
      "3    2012-01-07 02:27:01.000000000  5.764706e-06   \n",
      "4    2012-01-07 12:00:00.000000000  1.000000e-09   \n",
      "..                             ...           ...   \n",
      "411  2017-09-06 00:00:00.000000000  1.000000e-09   \n",
      "412  2017-09-09 08:01:07.753754283  1.000000e-09   \n",
      "413  2017-10-01 01:19:00.999999999  1.000000e-09   \n",
      "414  2017-10-05 02:49:59.000000000  1.647059e-07   \n",
      "415  2017-10-06 16:35:59.000000000  5.411765e-07   \n",
      "\n",
      "                                                New_ID  \n",
      "0    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "1    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "2    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "3    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "4    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "..                                                 ...  \n",
      "411  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "412  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "413  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "414  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "415  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "\n",
      "[416 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDOBenchmark_example\\training\\11388\\2012_01_07_02_27_01_0\\2012-01-07T005701__131.jpg\n",
      "------------------------------\n",
      "11389_2012_01_01_19_06_00_0\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"New_ID\"][0])\n",
    "print(\"---\"*10)\n",
    "print(Reading_CSV[\"id\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building New data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "New_Start = []\n",
    "New_End = []\n",
    "New_Path = []\n",
    "\n",
    "for x_start, x_end, x_path in zip(Reading_CSV.start.values,Reading_CSV.end.values,Reading_CSV.New_ID.values):\n",
    "\n",
    "    x_start = x_start[0:10]\n",
    "    x_start = x_start.replace(\"-\",\"\")\n",
    "    x_start = np.array(x_start,dtype=\"float32\")\n",
    "\n",
    "    x_end = x_end[0:10]\n",
    "    x_end = x_end.replace(\"-\",\"\")\n",
    "    x_end = np.array(x_end,dtype=\"float32\")\n",
    "\n",
    "    New_Start.append(x_start)\n",
    "    New_End.append(x_end)\n",
    "    New_Path.append(x_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN START:  417\n",
      "LEN END:  417\n",
      "LEN PATH:  417\n"
     ]
    }
   ],
   "source": [
    "print(\"LEN START: \", len(New_Start))\n",
    "print(\"LEN END: \", len(New_End))\n",
    "print(\"LEN PATH: \", len(New_Path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120100.0\n",
      "--------------------\n",
      "20120100.0\n",
      "--------------------\n",
      "SDOBenchmark_example\\training\\11388\\2012_01_07_02_27_01_0\\2012-01-07T005701__131.jpg\n"
     ]
    }
   ],
   "source": [
    "print(New_Start[0])\n",
    "print(\"--\"*10)\n",
    "print(New_End[0])\n",
    "print(\"--\"*10)\n",
    "print(New_Path[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "Start_Series = pd.Series(New_Start,name=\"START\").astype(np.float32)\n",
    "End_Series = pd.Series(New_End,name=\"END\").astype(np.float32)\n",
    "Path_Series = pd.Series(New_Path,name=\"PATH\").astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "Main_Data = pd.concat([Path_Series,Start_Series,End_Series],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  PATH       START         END\n",
      "0    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120100.0  20120100.0\n",
      "1    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120104.0  20120104.0\n",
      "2    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120104.0  20120106.0\n",
      "3    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120106.0  20120108.0\n",
      "4    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120108.0  20120108.0\n",
      "..                                                 ...         ...         ...\n",
      "411  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170904.0  20170906.0\n",
      "412  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170908.0  20170908.0\n",
      "413  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170930.0  20171000.0\n",
      "414  SDOBenchmark_example\\training\\11391\\2012_01_09...  20171004.0  20171004.0\n",
      "415  SDOBenchmark_example\\training\\11391\\2012_01_09...  20171006.0  20171006.0\n",
      "\n",
      "[416 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Main_Data.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vision\n",
    "Single"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2240c687850>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][33]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Example_IMG.shape)\n",
    "plt.ylabel(Example_IMG.size)\n",
    "plt.imshow(Example_IMG)\n",
    "\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "\n",
    "    Reading_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][indexing]),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    operations.set_xlabel(Reading_IMG.shape)\n",
    "    operations.set_ylabel(Reading_IMG.size)\n",
    "    operations.imshow(Reading_IMG)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2240d477f10>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2D\n",
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][13]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Example_IMG[:,:,0].shape)\n",
    "plt.ylabel(Example_IMG[:,:,0].size)\n",
    "plt.imshow(Example_IMG[:,:,0])\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Treshold image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2240d4e7550>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][13]),cv2.COLOR_BGR2RGB)\n",
    "_,Threshold_IMG = cv2.threshold(Example_IMG,200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Threshold_IMG.shape)\n",
    "plt.ylabel(Threshold_IMG.size)\n",
    "plt.imshow(Threshold_IMG)\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Varius other image types can be used such as Layer concat, Countours, Canny-treshold concat etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X_Start = []\n",
    "X_End = []\n",
    "X_Image = []\n",
    "\n",
    "for img,start_i, end_i in zip(Main_Data.PATH.values, Main_Data.START.values, Main_Data.END.values):\n",
    "    Picking_IMG = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "    Picking_IMG = cv2.resize(Picking_IMG, (180,180))\n",
    "    Picking_IMG = Picking_IMG / 255.\n",
    "\n",
    "    X_Image.append(Picking_IMG)\n",
    "    X_Start.append(start_i)\n",
    "    X_End.append(end_i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417,)\n",
      "(417,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.array(X_Image)))\n",
    "print(np.shape(np.array(X_Start)))\n",
    "print(np.shape(np.array(X_End)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "Train_JPG = np.array(X_Image,dtype = \"float32\")\n",
    "Train_START = np.array(X_Start,dtype=\"float32\")\n",
    "Train_END = np.array(X_End,dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(Train_JPG.shape)\n",
    "print(Train_START.shape)\n",
    "print(Train_END.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417,)\n",
      "(417,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "Scalar_Function = MinMaxScaler()\n",
    "\n",
    "Train_START_R = Scalar_Function.fit_transform(Train_START.reshape(-1,1))\n",
    "Train_END_R = Scalar_Function.fit_transform(Train_END.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auto-encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "X_Mask = []\n",
    "X_New_IMG = []\n",
    "\n",
    "for img_i in Main_Data.PATH.values:\n",
    "    Picking_IMG = cv2.cvtColor(cv2.imread(img_i),cv2.COLOR_BGR2RGB)\n",
    "    _,Threshold_IMG = cv2.threshold(Picking_IMG,200,255,cv2.THRESH_BINARY)\n",
    "    Canny_IMG = cv2.Canny(Threshold_IMG, 10,100)\n",
    "\n",
    "    Copy_Main = Picking_IMG.copy()\n",
    "    Copy_Main[Canny_IMG == 255] = [255,0,0]\n",
    "\n",
    "    Copy_Main = cv2.resize(Copy_Main, (180,180))\n",
    "    Copy_Main = Copy_Main / 255.\n",
    "\n",
    "    Picking_IMG = cv2.resize(Picking_IMG, (180,180))\n",
    "    Picking_IMG = Picking_IMG / 255.\n",
    "\n",
    "    X_Mask.append(Copy_Main)\n",
    "    X_New_IMG.append(Picking_IMG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "X_Mask = np.array(X_Mask,dtype=\"float32\")\n",
    "X_New_IMG = np.array(X_New_IMG,dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_New_IMG.shape)\n",
    "print(X_Mask.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ff1620ce",
   "language": "python",
   "display_name": "PyCharm (DataScience)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}