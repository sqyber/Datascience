{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import time\n",
    "#PATH PROCESS\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import nibabel as nib\n",
    "import csv\n",
    "#IMAGE PROCESS\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from scipy.ndimage.filters import convolve\n",
    "from skimage import data, io, filters\n",
    "import skimage\n",
    "from skimage.morphology import convex_hull_image, erosion\n",
    "from IPython import display\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import matplotlib.patches as patches\n",
    "#SCALER & TRANSFORMATION\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#ACCURACY CONTROL\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#OPTIMIZER\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n",
    "#MODEL LAYERS\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose,LeakyReLU, GaussianNoise, GlobalMaxPooling2D, ReLU, Input, Concatenate\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16,VGG19,inception_v3\n",
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import keras.utils\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import nvsmi\n",
    "#IGNORING WARNINGS\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "filterwarnings(\"ignore\", category=FutureWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": "'2.6.0'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying: Tensorflow gpu enable\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf. __version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much more complex and regressive problem related to predicting solar flares\n",
    "Goal is to create a deep learning model to predict solar flares based on the 800k jpeg dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up files and checking tables/csv's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "Main_Path = Path('SDOBenchmark_example/training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "Main_Train_CSV = list(Main_Path.glob(r\"**/*.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(Main_Train_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "Train_CSV = Main_Train_CSV[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDOBenchmark_example\\training\\meta_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(Train_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "Reading_CSV = pd.read_csv(Train_CSV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'start', 'end', 'peak_flux'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n"
     ]
    }
   ],
   "source": [
    "print(len(Reading_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id                          start  \\\n",
      "0    11389_2012_01_01_19_06_00_0  2012-01-01 07:06:00.000000000   \n",
      "1    11390_2012_01_03_02_22_01_1  2012-01-03 14:22:00.000000000   \n",
      "2    11392_2012_01_06_00_09_01_0  2012-01-05 12:09:01.000000000   \n",
      "3    11388_2012_01_07_02_27_01_0  2012-01-06 14:27:01.000000000   \n",
      "4    11394_2012_01_07_12_00_00_0  2012-01-07 00:00:00.000000000   \n",
      "..                           ...                            ...   \n",
      "411  12676_2017_09_03_12_00_00_5  2017-09-05 12:00:00.000000000   \n",
      "412  12674_2017_09_05_02_22_00_5  2017-09-08 20:01:07.753754283   \n",
      "413  12683_2017_09_28_01_01_00_3  2017-09-30 13:19:00.999999999   \n",
      "414  12682_2017_10_05_02_49_59_0  2017-10-04 14:49:59.000000000   \n",
      "415  12683_2017_10_06_16_35_59_0  2017-10-06 04:35:59.000000000   \n",
      "\n",
      "                               end     peak_flux  \n",
      "0    2012-01-01 19:06:00.000000000  1.882353e-06  \n",
      "1    2012-01-04 02:22:00.000000000  7.529412e-07  \n",
      "2    2012-01-06 00:09:01.000000000  3.058824e-06  \n",
      "3    2012-01-07 02:27:01.000000000  5.764706e-06  \n",
      "4    2012-01-07 12:00:00.000000000  1.000000e-09  \n",
      "..                             ...           ...  \n",
      "411  2017-09-06 00:00:00.000000000  1.000000e-09  \n",
      "412  2017-09-09 08:01:07.753754283  1.000000e-09  \n",
      "413  2017-10-01 01:19:00.999999999  1.000000e-09  \n",
      "414  2017-10-05 02:49:59.000000000  1.647059e-07  \n",
      "415  2017-10-06 16:35:59.000000000  5.411765e-07  \n",
      "\n",
      "[416 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           0\n",
      "start        0\n",
      "end          0\n",
      "peak_flux    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8823529411764705e-06\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"peak_flux\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-04 14:49:59.000000000\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"start\"][414])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-04\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"start\"][414][0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform date and time to a useable form"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Reading_CSV[\"start\"][414][0:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "Test_Date_Transform = Reading_CSV[\"start\"][414][0:10].replace(\"-\",\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171004\n"
     ]
    }
   ],
   "source": [
    "print(Test_Date_Transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "Test_Date_Array = np.array(int(Test_Date_Transform))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Test_Date_Array))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin Data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "JPG_Path = list(Main_Path.glob(r\"**/*.jpg\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "Sorted_JPG_Path = sorted(JPG_Path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "Reading_CSV[\"New_ID\"] = Sorted_JPG_Path[40:457]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id                          start  \\\n",
      "0    11389_2012_01_01_19_06_00_0  2012-01-01 07:06:00.000000000   \n",
      "1    11390_2012_01_03_02_22_01_1  2012-01-03 14:22:00.000000000   \n",
      "2    11392_2012_01_06_00_09_01_0  2012-01-05 12:09:01.000000000   \n",
      "3    11388_2012_01_07_02_27_01_0  2012-01-06 14:27:01.000000000   \n",
      "4    11394_2012_01_07_12_00_00_0  2012-01-07 00:00:00.000000000   \n",
      "..                           ...                            ...   \n",
      "411  12676_2017_09_03_12_00_00_5  2017-09-05 12:00:00.000000000   \n",
      "412  12674_2017_09_05_02_22_00_5  2017-09-08 20:01:07.753754283   \n",
      "413  12683_2017_09_28_01_01_00_3  2017-09-30 13:19:00.999999999   \n",
      "414  12682_2017_10_05_02_49_59_0  2017-10-04 14:49:59.000000000   \n",
      "415  12683_2017_10_06_16_35_59_0  2017-10-06 04:35:59.000000000   \n",
      "\n",
      "                               end     peak_flux  \\\n",
      "0    2012-01-01 19:06:00.000000000  1.882353e-06   \n",
      "1    2012-01-04 02:22:00.000000000  7.529412e-07   \n",
      "2    2012-01-06 00:09:01.000000000  3.058824e-06   \n",
      "3    2012-01-07 02:27:01.000000000  5.764706e-06   \n",
      "4    2012-01-07 12:00:00.000000000  1.000000e-09   \n",
      "..                             ...           ...   \n",
      "411  2017-09-06 00:00:00.000000000  1.000000e-09   \n",
      "412  2017-09-09 08:01:07.753754283  1.000000e-09   \n",
      "413  2017-10-01 01:19:00.999999999  1.000000e-09   \n",
      "414  2017-10-05 02:49:59.000000000  1.647059e-07   \n",
      "415  2017-10-06 16:35:59.000000000  5.411765e-07   \n",
      "\n",
      "                                                New_ID  \n",
      "0    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "1    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "2    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "3    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "4    SDOBenchmark_example\\training\\11388\\2012_01_07...  \n",
      "..                                                 ...  \n",
      "411  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "412  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "413  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "414  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "415  SDOBenchmark_example\\training\\11391\\2012_01_09...  \n",
      "\n",
      "[416 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDOBenchmark_example\\training\\11388\\2012_01_07_02_27_01_0\\2012-01-07T005701__131.jpg\n",
      "------------------------------\n",
      "11389_2012_01_01_19_06_00_0\n"
     ]
    }
   ],
   "source": [
    "print(Reading_CSV[\"New_ID\"][0])\n",
    "print(\"---\"*10)\n",
    "print(Reading_CSV[\"id\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building New data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "New_Start = []\n",
    "New_End = []\n",
    "New_Path = []\n",
    "\n",
    "for x_start, x_end, x_path in zip(Reading_CSV.start.values,Reading_CSV.end.values,Reading_CSV.New_ID.values):\n",
    "\n",
    "    x_start = x_start[0:10]\n",
    "    x_start = x_start.replace(\"-\",\"\")\n",
    "    x_start = np.array(x_start,dtype=\"float32\")\n",
    "\n",
    "    x_end = x_end[0:10]\n",
    "    x_end = x_end.replace(\"-\",\"\")\n",
    "    x_end = np.array(x_end,dtype=\"float32\")\n",
    "\n",
    "    New_Start.append(x_start)\n",
    "    New_End.append(x_end)\n",
    "    New_Path.append(x_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN START:  417\n",
      "LEN END:  417\n",
      "LEN PATH:  417\n"
     ]
    }
   ],
   "source": [
    "print(\"LEN START: \", len(New_Start))\n",
    "print(\"LEN END: \", len(New_End))\n",
    "print(\"LEN PATH: \", len(New_Path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120100.0\n",
      "--------------------\n",
      "20120100.0\n",
      "--------------------\n",
      "SDOBenchmark_example\\training\\11388\\2012_01_07_02_27_01_0\\2012-01-07T005701__131.jpg\n"
     ]
    }
   ],
   "source": [
    "print(New_Start[0])\n",
    "print(\"--\"*10)\n",
    "print(New_End[0])\n",
    "print(\"--\"*10)\n",
    "print(New_Path[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "Start_Series = pd.Series(New_Start,name=\"START\").astype(np.float32)\n",
    "End_Series = pd.Series(New_End,name=\"END\").astype(np.float32)\n",
    "Path_Series = pd.Series(New_Path,name=\"PATH\").astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "Main_Data = pd.concat([Path_Series,Start_Series,End_Series],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  PATH       START         END\n",
      "0    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120100.0  20120100.0\n",
      "1    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120104.0  20120104.0\n",
      "2    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120104.0  20120106.0\n",
      "3    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120106.0  20120108.0\n",
      "4    SDOBenchmark_example\\training\\11388\\2012_01_07...  20120108.0  20120108.0\n",
      "..                                                 ...         ...         ...\n",
      "411  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170904.0  20170906.0\n",
      "412  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170908.0  20170908.0\n",
      "413  SDOBenchmark_example\\training\\11391\\2012_01_09...  20170930.0  20171000.0\n",
      "414  SDOBenchmark_example\\training\\11391\\2012_01_09...  20171004.0  20171004.0\n",
      "415  SDOBenchmark_example\\training\\11391\\2012_01_09...  20171006.0  20171006.0\n",
      "\n",
      "[416 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Main_Data.head(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing various image display configurations\n",
    "Vision\n",
    "Single"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x26a8f31a070>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][33]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Example_IMG.shape)\n",
    "plt.ylabel(Example_IMG.size)\n",
    "plt.imshow(Example_IMG)\n",
    "\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
    "\n",
    "for indexing,operations in enumerate(axis.flat):\n",
    "\n",
    "    Reading_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][indexing]),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    operations.set_xlabel(Reading_IMG.shape)\n",
    "    operations.set_ylabel(Reading_IMG.size)\n",
    "    operations.imshow(Reading_IMG)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x26a926fcc70>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2D\n",
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][13]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Example_IMG[:,:,0].shape)\n",
    "plt.ylabel(Example_IMG[:,:,0].size)\n",
    "plt.imshow(Example_IMG[:,:,0])\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Treshold image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x26a92b4a400>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example_IMG = cv2.cvtColor(cv2.imread(Main_Data[\"PATH\"][13]),cv2.COLOR_BGR2RGB)\n",
    "_,Threshold_IMG = cv2.threshold(Example_IMG,200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xlabel(Threshold_IMG.shape)\n",
    "plt.ylabel(Threshold_IMG.size)\n",
    "plt.imshow(Threshold_IMG)\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Varius other image types can be used such as Layer concat, Countours, Canny-treshold concat etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data transformation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "X_Start = []\n",
    "X_End = []\n",
    "X_Image = []\n",
    "\n",
    "for img,start_i, end_i in zip(Main_Data.PATH.values, Main_Data.START.values, Main_Data.END.values):\n",
    "    Picking_IMG = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "    Picking_IMG = cv2.resize(Picking_IMG, (180,180))\n",
    "    Picking_IMG = Picking_IMG / 255.\n",
    "\n",
    "    X_Image.append(Picking_IMG)\n",
    "    X_Start.append(start_i)\n",
    "    X_End.append(end_i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417,)\n",
      "(417,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.array(X_Image)))\n",
    "print(np.shape(np.array(X_Start)))\n",
    "print(np.shape(np.array(X_End)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "Train_JPG = np.array(X_Image,dtype = \"float32\")\n",
    "Train_START = np.array(X_Start,dtype=\"float32\")\n",
    "Train_END = np.array(X_End,dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(Train_JPG.shape)\n",
    "print(Train_START.shape)\n",
    "print(Train_END.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417,)\n",
      "(417,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "Scalar_Function = MinMaxScaler()\n",
    "\n",
    "Train_START_R = Scalar_Function.fit_transform(Train_START.reshape(-1,1))\n",
    "Train_END_R = Scalar_Function.fit_transform(Train_END.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auto-encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_Mask = []\n",
    "X_New_IMG = []\n",
    "\n",
    "for img_i in Main_Data.PATH.values:\n",
    "    Picking_IMG = cv2.cvtColor(cv2.imread(img_i),cv2.COLOR_BGR2RGB)\n",
    "    _,Threshold_IMG = cv2.threshold(Picking_IMG,200,255,cv2.THRESH_BINARY)\n",
    "    Canny_IMG = cv2.Canny(Threshold_IMG, 10,100)\n",
    "\n",
    "    Copy_Main = Picking_IMG.copy()\n",
    "    Copy_Main[Canny_IMG == 255] = [255,0,0]\n",
    "\n",
    "    Copy_Main = cv2.resize(Copy_Main, (180,180))\n",
    "    Copy_Main = Copy_Main / 255.\n",
    "\n",
    "    Picking_IMG = cv2.resize(Picking_IMG, (180,180))\n",
    "    Picking_IMG = Picking_IMG / 255.\n",
    "\n",
    "    X_Mask.append(Copy_Main)\n",
    "    X_New_IMG.append(Picking_IMG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "X_Mask = np.array(X_Mask,dtype=\"float32\")\n",
    "X_New_IMG = np.array(X_New_IMG,dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417, 180, 180, 3)\n",
      "(417, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_New_IMG.shape)\n",
    "print(X_Mask.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 179.5, 179.5, -0.5)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure,axis = plt.subplots(1,2, figsize=(15,15))\n",
    "\n",
    "axis[0].imshow(X_New_IMG[0])\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(X_Mask[0])\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "(-0.5, 179.5, 179.5, -0.5)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure,axis = plt.subplots(1,2, figsize=(15,15))\n",
    "\n",
    "axis[0].imshow(X_New_IMG[100])\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(X_Mask[100])\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encoder model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters / Callbacks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\n",
    "Checkpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\", save_best_only=True, save_weights_only=True, filepath=\"./modelcheck\")\n",
    "Reduce_Model = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "compile_loss = \"binary_crossentropy\"\n",
    "compile_optimizers = Adam(lr=0.0000001)\n",
    "output_class = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Structure, building model layers. 4 convolution layers into 4 transposed convolutions. he_normal weights matrix and padding for dimension consistency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "E_AE = Sequential()\n",
    "\n",
    "E_AE.add(Conv2D(32,(5,5), kernel_initializer= 'he_normal', use_bias=True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "E_AE.add(Conv2D(64,(5,5), kernel_initializer= 'he_normal',use_bias= True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "E_AE.add(Conv2D(128,(5,5), kernel_initializer= 'he_normal', use_bias= True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "E_AE.add(Conv2D(256,(5,5), kernel_initializer= 'he_normal', use_bias=True, padding=\"valid\"))\n",
    "E_AE.add(BatchNormalization())\n",
    "E_AE.add(ReLU())\n",
    "\n",
    "D_AE = Sequential()\n",
    "\n",
    "D_AE.add(Conv2DTranspose(128,(5,5), padding=\"valid\"))\n",
    "D_AE.add(ReLU())\n",
    "\n",
    "D_AE.add(Conv2DTranspose(64,(5,5), padding=\"valid\"))\n",
    "D_AE.add(ReLU())\n",
    "\n",
    "D_AE.add(Conv2DTranspose(32,(5,5), padding=\"valid\"))\n",
    "D_AE.add(ReLU())\n",
    "\n",
    "D_AE.add(Conv2DTranspose(output_class,(5,5)))\n",
    "D_AE.add(ReLU())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'E_AE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-50-5d6c02006f71>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mAuto_Encoder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mE_AE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mD_AE\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mAuto_Encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcompile_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcompile_optimizers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"mse\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'E_AE' is not defined"
     ]
    }
   ],
   "source": [
    "Auto_Encoder = Sequential([E_AE, D_AE])\n",
    "Auto_Encoder.compile(loss=compile_loss, optimizer=compile_optimizers, metrics=[\"mse\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Model_Autoencoder = Auto_Encoder.fit(X_New_IMG, X_Mask, epochs=55, callbacks=[Checkpoint_Model])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 49,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Auto_Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-49-ca56a27452a7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mModel_Autoencoder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAuto_Encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_New_IMG\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_Mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m55\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mCheckpoint_Model\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'Auto_Encoder' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Auto_Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-9a95e288f06a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mPrediction_MASK_Seen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAuto_Encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_New_IMG\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mfigure\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0maxis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubplots\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mpre_img_number\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mOriginal_Img\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX_New_IMG\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpre_img_number\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Auto_Encoder' is not defined"
     ]
    }
   ],
   "source": [
    "Prediction_MASK_Seen = Auto_Encoder.predict(X_New_IMG[:20])\n",
    "figure,axis = plt.subplots(1,2,figsize=(15,15))\n",
    "pre_img_number = 1\n",
    "\n",
    "Original_Img = X_New_IMG[pre_img_number]\n",
    "Predict_Mask = Prediction_MASK_Seen[pre_img_number]\n",
    "\n",
    "axis[0].imshow(Original_Img)\n",
    "axis[0].set_xlabel(Original_Img.shape)\n",
    "axis[0].set_ylabel(Original_Img.size)\n",
    "axis[0].set_title(\"IMAGE\")\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(Predict_Mask)\n",
    "axis[1].set_xlabel(Predict_Mask.shape)\n",
    "axis[1].set_ylabel(Predict_Mask.size)\n",
    "axis[1].set_title(\"PREDICTION\")\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#predict test sets\n",
    "Reading_IMG = cv2.cvtColor(cv2.imread(\"../input/sdobenchmark/SDOBenchmark_example/test/11476/2012_05_14_16_18_57_0/2012-05-14T041857__335.jpg\"),cv2.COLOR_BGR2RGB)\n",
    "Reading_IMG = cv2.resize(Reading_IMG,(180,180))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Reading_IMG_Shape = Reading_IMG.reshape(1,Reading_IMG.shape[0],Reading_IMG.shape[1],Reading_IMG.shape[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(Reading_IMG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#testing random predicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MASK_Seen = Auto_Encoder.predict(Reading_IMG_Shape)\n",
    "figure,axis = plt.subplots(1,2,figsize=(14,14))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "axis[0].imshow(Reading_IMG)\n",
    "axis[0].set_xlabel(Reading_IMG.shape)\n",
    "axis[0].set_ylabel(Reading_IMG.size)\n",
    "axis[0].set_title(\"IMAGE\")\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(MASK_Seen[0])\n",
    "axis[1].set_xlabel(MASK_Seen[0].shape)\n",
    "axis[1].set_ylabel(MASK_Seen[0].size)\n",
    "axis[1].set_title(\"PREDICTION\")\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = Sequential()\n",
    "encoder.add(Flatten(input_shape=[180,180,3]))\n",
    "encoder.add(Dense(300,activation=\"relu\"))\n",
    "encoder.add(Dense(200,activation=\"relu\"))\n",
    "encoder.add(Dense(100,activation=\"relu\"))\n",
    "encoder.add(Dense(50,activation=\"relu\"))\n",
    "encoder.add(Dense(25,activation=\"relu\"))\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(50,input_shape=[25],activation=\"relu\"))\n",
    "decoder.add(Dense(100,activation=\"relu\"))\n",
    "decoder.add(Dense(200,activation=\"relu\"))\n",
    "decoder.add(Dense(300,activation=\"relu\"))\n",
    "decoder.add(Dense(180*180*3,activation=\"sigmoid\"))\n",
    "decoder.add(Reshape([180,180,3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AutoEncoder_II = Sequential([encoder,decoder])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AutoEncoder_II.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=[\"mse\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AutoEncoder_II.fit(X_New_IMG,X_New_IMG,epochs=40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PRE_Img = AutoEncoder_II.predict(X_New_IMG[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(1,2,figsize=(14,14))\n",
    "pre_img_number = 1\n",
    "\n",
    "Original_Img = X_New_IMG[pre_img_number]\n",
    "Predict_Reduce = PRE_Img[pre_img_number]\n",
    "\n",
    "axis[0].imshow(Original_Img)\n",
    "axis[0].set_xlabel(Original_Img.shape)\n",
    "axis[0].set_ylabel(Original_Img.size)\n",
    "axis[0].set_title(\"IMAGE\")\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(Predict_Reduce)\n",
    "axis[1].set_xlabel(Predict_Reduce.shape)\n",
    "axis[1].set_ylabel(Predict_Reduce.size)\n",
    "axis[1].set_title(\"PREDICTION\")\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure,axis = plt.subplots(1,2,figsize=(14,14))\n",
    "pre_img_number = 2\n",
    "\n",
    "Original_Img = X_New_IMG[pre_img_number]\n",
    "Predict_Reduce = PRE_Img[pre_img_number]\n",
    "\n",
    "axis[0].imshow(Original_Img)\n",
    "axis[0].set_xlabel(Original_Img.shape)\n",
    "axis[0].set_ylabel(Original_Img.size)\n",
    "axis[0].set_title(\"IMAGE\")\n",
    "axis[0].axis(\"off\")\n",
    "axis[1].imshow(Predict_Reduce)\n",
    "axis[1].set_xlabel(Predict_Reduce.shape)\n",
    "axis[1].set_ylabel(Predict_Reduce.size)\n",
    "axis[1].set_title(\"PREDICTION\")\n",
    "axis[1].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ff1620ce",
   "language": "python",
   "display_name": "PyCharm (DataScience)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}